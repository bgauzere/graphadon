{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graph Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This practical work is devoted to the discovery of graph machine learning using Graph Neural Network, on a simple and classic classification experiment, namely the [MUTAG dataset](). \n",
    "\n",
    "Before starting to work, we will check that our kernel configuration is ok. Execute the next cell, you should have no error. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "os.environ['TORCH'] = torch.__version__\n",
    "print(torch.__version__)\n",
    "\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Loading\n",
    "\n",
    "\n",
    "The MUTAG dataset is a classic classification dataset used in graph machine learning. It consists of a collection of mutagenic aromatic and heteroaromatic nitro compounds. The goal is to predict whether a compound is mutagenic or non-mutagenic based on its molecular structure.\n",
    "\n",
    "The dataset contains a set of graphs, where each graph represents a compound. Each node in the graph represents an atom in the compound, and the edges represent the bonds between atoms. The nodes carry the atom types as attributes and the edges the kind of atomic bond.\n",
    "\n",
    "The dataset is labeled, with each graph labeled as either mutagenic or non-mutagenic. This makes it a binary graph classification problem.\n",
    "\n",
    "The following code imports the `TUDataset` class from `torch_geometric.datasets` module and creates an instance of the dataset by specifying the root directory where the data will be locally stored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.datasets import TUDataset\n",
    "\n",
    "\n",
    "dataset_path = \"data/TUDataset\"\n",
    "dataset = TUDataset(root=dataset_path, name='MUTAG')\n",
    "\n",
    "dataset.download()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data exploration\n",
    "\n",
    "By looking, at the size of the dataset, we can retrieve the number of compounds. Each item in the dataset corresponds to a graph, and each item of `dataset.y` corresponds to the class of the compound."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = dataset[0]\n",
    "print(graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To visualize a molecule, we can rely on `networkx` library. Note that nodes attributes encode the atom type as a one hot encoding, the same with edge attributes and kind of atomic bond.\n",
    "\n",
    "What are the possible node's and edge's labels ? How many nodes for the first graph ? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.utils import to_networkx\n",
    "g = to_networkx(graph, node_attrs='x')\n",
    "nx.draw(g, with_labels=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre processing the dataset\n",
    "\n",
    "rappel de l'importance de séparer train et test, bonne pratique avec pytorch geometric\n",
    "présentation des dataloader, notion de batch, shuffle oui/non\n",
    "\n",
    "\n",
    "To make a good model, we want to evaluate its performance on a test set, not used during the learning phase. This separation can be done by keeping by splitting the dataset object using slices of `train_test_split` from scikit-learn library.\n",
    "\n",
    "Once this separation is performed, we create two dataloaders. The DataLoader class is used to load data in batches during the training and testing phases of a machine learning model. It helps in efficiently processing large datasets by dividing them into smaller batches. \n",
    "\n",
    "By using these DataLoader objects, you can iterate over the data in batches during the training and testing phases of your model. This allows you to efficiently process large datasets and train your model more effectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_dataset, test_dataset = train_test_split(dataset, train_size=.8, random_state=42) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.loader import DataLoader\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the batch sizes\n",
    "for data in train_loader:\n",
    "    print(len(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A first GNN \n",
    "\n",
    "To create our first GNN prediction model, we will rely on a model implemented using the Pytorch Geometric library in the `graphadon.py`file. We will first use it as a black box, and then try to understand its components.\n",
    "\n",
    "![./figures/graph_level.svg](./figures/graph_level.svg)\n",
    "\n",
    "Create an instance of `FirstGNN` with the default parameters and print the instance.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from graphadon import FirstGNN\n",
    "\n",
    "num_node_features = dataset.num_node_features\n",
    "model = FirstGNN()\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Learning\n",
    "\n",
    "Once our architecture has been created, we need to tune its parameters to fit a particular task, here our classification task. As a classic MLP or CNN, the learning loop follows the same backbone : \n",
    " 1. Forward pass\n",
    " 1. Gradient computation\n",
    " 1. Backward pass\n",
    " 1. Reinitialisation of gradients.\n",
    "\n",
    "Complete the following code to learn the parameters of our `FirstGNN`.\n",
    "For each epoch, compute the loss and the accuracy performance on train set. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "NB_EPOCHS = ...\n",
    "\n",
    "for epoch in tqdm(range(1, NB_EPOCHS+1)):\n",
    "    model.train()\n",
    "    for data in train_loader:  # Pour chaque mini batch\n",
    "        # forward pass. What the GNN need to perform the forward pass ?\n",
    "        out = model.forward(data.x, data.edge_index, data.batch) \n",
    "        loss = criterion(out, data.y)   # calcul de la loss\n",
    "        loss.backward()  #calcul des gradients  \n",
    "        \n",
    "        \n",
    "        optimizer.step()  # Rétro propagation \n",
    "        optimizer.zero_grad()  # on remet à 0 pour le prochain tour\n",
    "    \n",
    "    model.eval()\n",
    "    # test de l'accuracy sur le train \n",
    "    for data in train_loader: \n",
    "        out = model.forward(data.x, data.edge_index, data.batch) \n",
    "        pred = out.argmax(dim=1) # décider de qui a gagné\n",
    "    accuracy = ...\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning curves\n",
    "\n",
    "To be sure that everything went well, plot the learning curves according to the loss and the accuracy on train set.\n",
    "\n",
    "Are the curves following your expectations ? \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction\n",
    "\n",
    "For now, we only check the performance on data we already know the properties, which is quite useless. Let's evaluate our model on test set. \n",
    "\n",
    "Compute the accuracy on test set and compare it to the accuracy on train set. \n",
    "\n",
    "What's your opinion on the computed value ? \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval() # utile pour les dropout \n",
    "\n",
    "for data in test_loader:  \n",
    "    ...\n",
    "acc = ...\n",
    "print('Accuracy: {:.4f}'.format(acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add a validation set\n",
    "\n",
    "Let's now evaluate the performance on our test set (which hence becomes a validation set) for each epoch. \n",
    "\n",
    "1. Complete the function test to get the accuracy of a pair of model/dataloader\n",
    "2. Modify your learning curve to compute accuracy on both learning/validation set\n",
    "3. Draw the learning curves \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, loader):\n",
    "    \"\"\"Compute the accuracy on loader using model\"\"\"\n",
    "    acc = ...\n",
    "    return correct / len(loader.dataset)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GNN Implementation\n",
    "\n",
    "Now we are able to train a predictive model as a black box, let's go into details and analyze how this GNN is built. \n",
    "\n",
    "### Layer Analysis\n",
    "\n",
    "1. Open the file `graphadon.py` and analyse the contents of the `FirstGNN` class. What layers do you identify ?\n",
    "> Note that you can heavily rely on the documentation of `pytorch geometric` : [https://pytorch-geometric.readthedocs.io/en/latest/modules/nn.html]()\n",
    "\n",
    "2. Add a convolutional layer followed by a ReLU. \n",
    "> Congrats ! You implemented your first GNN, now you can test it. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### So many convolutions \n",
    "\n",
    "Change the convolutional layers to  `GraphConv` and test your new model. \n",
    "\n",
    "You can also pick among the many layers available : https://pytorch-geometric.readthedocs.io/en/latest/modules/nn.html#convolutional-layers\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Readout/Pooling\n",
    "\n",
    "In the first GNN implemented, we inserted a `global_mean_pooling` layer. \n",
    "\n",
    "1. What is the rationale of this function ? What happen if we remove it ? \n",
    "2. Change this function to another readout strategy and test the new model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Hyperparameters\n",
    "\n",
    "GNNs architectures open a lot of new possibilities but they come with a strong drawback : tuning hyperaparemeters.\n",
    "\n",
    "1. Identify the hyperparameters for the different layers, the model itself and the optimization algorithm.\n",
    "\n",
    "2. Propose a strategy to find the best combination \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Competition \n",
    "\n",
    "Since you are now a new expert on GNNs, let's compete. We created on Kaggle a private leaderboard to test your skills on another dataset encoding molecular compounds : [Kaggle Competition](https://www.kaggle.com/competitions/graphadon-contest)\n",
    "\n",
    "Here's your invitation link : https://www.kaggle.com/t/aa069d65592d4d15ba457898007e7540\n",
    "\n",
    "It's still a binary classification task, but now you only have access to the graph of the test set, but not their properties to predict ! \n",
    "\n",
    "To compete, you will need to learn a model using the `train_dataset` provided in `train_dataset.pt` file. The submission file for Kaggle competition can be obtained using the `generate_pred_for_kaggle` and `generate_kaggle_file` functions provided in `graphadon.py` file. Check the example using FirstGNN as a source of inspiration.\n",
    "\n",
    "The train dataset is composed of 2168 molecules, where each node is encoded by 14 binary values corresponding to a one hot encoding of the corresponding atom. Test set is composed of 2169 molecules and encoded in the same way as the train set, except the `y` value.\n",
    "\n",
    "Do your best ! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "\n",
    "train_dataset = torch.load(\"./train_dataset.pt\")\n",
    "test_dataset = torch.load(\"./test_dataset.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from graphadon import FirstGNN\n",
    "from graphadon import learn_and_perf\n",
    "\n",
    "model = FirstGNN()\n",
    "\n",
    "acc_train, acc_test, losses  = learn_and_perf(model, train_loader, None, nb_epochs=100)\n",
    "\n",
    "plt.plot(acc_train, label=\"train\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from graphadon import generate_pred_for_kaggle, generate_kaggle_file\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "preds = generate_pred_for_kaggle(model, test_loader)\n",
    "generate_kaggle_file(preds, \"./kaggle.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "graphadon",
   "language": "python",
   "name": "graphadon"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
